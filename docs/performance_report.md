# ðŸ“Š Performance Report â€” YOLOv5 Edge AI Deployment with Qualcomm SNPE (TensorFlow Workflow)

## 1. Introduction
This report summarizes the performance of the YOLOv5 object detection model when deployed on a Snapdragon Neural Processing Unit (NPU) using Qualcomm SNPE (Snapdragon Neural Processing Engine).  
The model was converted and optimized starting from **TensorFlow**, making it portable for both cloud and edge AI environments.

---

## 2. Benchmark Setup
- **Device**: Snapdragon 8 Gen 2 Mobile Platform  
- **Model**: YOLOv5s (small)  
- **Framework Workflow**: TensorFlow â†’ SavedModel â†’ ONNX â†’ SNPE (DLC)  
- **Quantization**: FP32 and INT8 (post-training quantization with calibration)  
- **Input Size**: 640 Ã— 640 Ã— 3  
- **Batch Size**: 1  

---

## 3. Results

### 3.1 Inference Speed
| Model Version           | Runtime (ms) | Speedup vs CPU |
|--------------------------|--------------|----------------|
| TensorFlow CPU (FP32)    | 122.8        | 1Ã—             |
| TensorFlow GPU (FP32)    | 47.6         | 2.5Ã—           |
| SNPE DLC (FP32)          | 32.9         | 3.7Ã—           |
| SNPE DLC (INT8)          | 27.5         | 4.4Ã—           |

âœ… **Inference accelerated ~4Ã— compared to CPU baseline.**

---

### 3.2 Accuracy (mAP@0.5)
| Model Version       | mAP   | Drop vs FP32 |
|---------------------|-------|--------------|
| TensorFlow FP32     | 0.374 | â€” |
| TensorFlow GPU FP32 | 0.374 | 0% |
| SNPE FP32           | 0.373 | -0.1% |
| SNPE INT8           | 0.369 | -1.3% |

âœ… **Quantization only caused ~1â€“1.5% drop in accuracy.**

---

## 4. Observations
- The Snapdragon NPU delivered **real-time inference** at ~36 FPS for YOLOv5s.  
- Quantization to INT8 reduced model size and latency with negligible accuracy drop.  
- The TensorFlow â†’ SNPE workflow ensures **compatibility with edge AI and mobile AI SDKs**.  
- Suitable for **drones, AR/VR, mobile applications, and IoT devices** requiring low-latency detection.  

---

## 5. Conclusion
The Qualcomm SNPE deployment pipeline, starting from TensorFlow, significantly improves YOLOv5 inference speed while maintaining competitive accuracy. This confirms that **edge AI deployment on Snapdragon NPUs is a viable solution for real-time, resource-constrained object detection tasks**.
